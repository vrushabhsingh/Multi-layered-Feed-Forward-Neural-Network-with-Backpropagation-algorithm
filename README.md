Introduction :
The Backpropagation algorithm is used for training of multilayer feed-forward
networks from the field of Artificial Neural Networks.
The principle is to model a given function by modifying internal weightings of
input signals to produce an expected output signal.
Here, we take a simple problem containing a fixed number of input,output and
hidden neurons and learning rate.

Methodology :
Number of hidden layers is predicted based on the Trial and error method.
Learning rate is fixed to 0.5 because the number of data inputs we are giving
to the input layer is less so we can have a higher value for learning rate which
gives higher convergence rate to the solution.
The program is run for a fixed number of epochs,obtained from the user.

Result :
Since the given learning rate is pretty high we get convergence in a short
number of iterations and also the error obtained at the end will be 0.01.

Conclusion :
Learning rate : Based on the number of input data this value will be decided.
Number of neurons in hidden layer : This can be determined by Trial and error
method. We can also optimise the number of neurons in the hidden layer
based on the type of problem. For complex neural networks we go for
optimization or else for simple problems we can go for trial and error method.
